{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZfAtK74VaGHi"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten,Subtract, Lambda, Concatenate\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.metrics import Precision, Recall, Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QAoAv6lp9KTA",
        "outputId": "b3335c0a-a566-4a6b-cad2-db5c4470f8bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 200"
      ],
      "metadata": {
        "id": "46ojgEa69VWj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_class_file_paths(path):\n",
        "    classes = os.listdir(path)\n",
        "    file_paths = {}\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(path, class_name)\n",
        "        file_paths[class_name] = tf.data.Dataset.list_files(class_path + '/*.jpg')\n",
        "    return file_paths"
      ],
      "metadata": {
        "id": "Dx7PWP1_9YwQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(file_path):\n",
        "\n",
        "    byte_img = tf.io.read_file(file_path)\n",
        "    img = tf.io.decode_jpeg(byte_img)\n",
        "\n",
        "    img = tf.image.resize(img, (SIZE,SIZE))\n",
        "    img = img / 255.0\n",
        "\n",
        "    return img"
      ],
      "metadata": {
        "id": "7b_GHXNp9dsa"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_twin(input_img, validation_img, label):\n",
        "    return (preprocess(input_img), preprocess(validation_img), label)\n"
      ],
      "metadata": {
        "id": "3cVC_EXf9iUP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_embedding():\n",
        "    inp = Input(shape=(SIZE,SIZE,1), name='input_image')\n",
        "\n",
        "    c1 = Conv2D(64, (10,10), activation='relu')(inp)\n",
        "    m1 = MaxPooling2D(64, (2,2), padding='same')(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (7,7), activation='relu')(m1)\n",
        "    m2 = MaxPooling2D(64, (2,2), padding='same')(c2)\n",
        "\n",
        "    c3 = Conv2D(128, (4,4), activation='relu')(m2)\n",
        "    m3 = MaxPooling2D(64, (2,2), padding='same')(c3)\n",
        "\n",
        "    c4 = Conv2D(256, (4,4), activation='relu')(m3)\n",
        "    f1 = Flatten()(c4)\n",
        "    d1 = Dense(4096, activation='sigmoid')(f1)\n",
        "\n",
        "\n",
        "    return Model(inputs=[inp], outputs=[d1], name='embedding')"
      ],
      "metadata": {
        "id": "SUcIK-ZM99cr"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding = make_embedding()"
      ],
      "metadata": {
        "id": "vJkPHl2C-E5g"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Siamese L1 Distance class\n",
        "class L1Dist(Layer):\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "\n",
        "    def call(self, input_embedding, validation_embedding):\n",
        "        return tf.math.abs(input_embedding - validation_embedding)"
      ],
      "metadata": {
        "id": "aOaPLibX-Jwa"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reload model\n",
        "siamese_model = tf.keras.models.load_model('/content/drive/MyDrive/log_id_project/model/siamesemodel_gray_cnn.h5',\n",
        "                                   custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
      ],
      "metadata": {
        "id": "y6kDh-W7-Ov-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4bf08f4-0bd9-42f2-8d1c-079dae7a50c1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input image path, reference image where we need to verify the identity. The image should me preprocessed and grayscale\n",
        "input_path = '/content/drive/MyDrive/log_id_project/data/database/input/input_pine4.jpg'\n",
        "#folder path where the tree images locate. One image per each tree. tree name is the file name\n",
        "validation_path = '/content/drive/MyDrive/log_id_project/data/database/verification'"
      ],
      "metadata": {
        "id": "pl_BKzrwOhxE"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def verify(model,detection_threshold):\n",
        "    results = {}\n",
        "    for image in os.listdir(os.path.join(validation_path)):\n",
        "        input_img = preprocess(os.path.join(input_path))\n",
        "        validation_img = preprocess(os.path.join(validation_path, image))\n",
        "        tree_name = os.path.splitext(os.path.basename(image))[0]\n",
        "        result = model.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
        "        if result > detection_threshold:\n",
        "            results[tree_name] = result\n",
        "\n",
        "    print(results)\n",
        "\n",
        "\n",
        "    if len(results)==1:\n",
        "      end_result = f\"This tree is {list(results.keys())[0]}\"\n",
        "    elif len(results)>1:\n",
        "      end_result = f\"This tree is {max(results, key=results.get)}\"\n",
        "    else:\n",
        "      end_result = \"This tree is not in the database\"\n",
        "\n",
        "\n",
        "    return end_result"
      ],
      "metadata": {
        "id": "iSk1BpBf-ixt"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end_result = verify(siamese_model,0.5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gedDH7MQ-X6K",
        "outputId": "f955bfa1-1bac-465f-e65b-14abdcd86c97"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "{'pine 4': array([[0.84521914]], dtype=float32)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "end_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CV8Z5W4t_9p1",
        "outputId": "1b894d6e-e87d-4e8a-8ff5-8a77cb99d7a1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This tree is pine 4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MfWrDwTFUneY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}